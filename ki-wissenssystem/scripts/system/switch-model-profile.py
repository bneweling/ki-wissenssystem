#!/usr/bin/env python3
"""
KI-Wissenssystem Model Profile Switcher
Ermöglicht einfaches Wechseln zwischen verschiedenen Modell-Profilen
"""

import os
import sys
import argparse
from pathlib import Path
from typing import Dict, Any

# Profil-Definitionen
PROFILES = {
    "premium": {
        "name": "Premium",
        "description": "Neueste Top-Modelle für maximale Performance (2025)",
        "cost": "Hoch",
        "performance": "Maximal",
        "models": {
            "classifier_model": "gemini-2.5-flash",
            "extractor_model": "gpt-4.1", 
            "synthesizer_model": "claude-opus-4-20250514",
            "validator_model_1": "gpt-4o",
            "validator_model_2": "claude-sonnet-4-20250514"
        },
        "required_apis": ["Google", "OpenAI", "Anthropic"]
    },
    "balanced": {
        "name": "Balanced",
        "description": "Optimale Balance mit neuesten Modellen",
        "cost": "Mittel",
        "performance": "Hoch",
        "models": {
            "classifier_model": "gemini-2.5-flash",
            "extractor_model": "gpt-4.1",
            "synthesizer_model": "gemini-2.5-pro",
            "validator_model_1": "o4-mini",
            "validator_model_2": "claude-3-7-sonnet-20250219"
        },
        "required_apis": ["Google", "OpenAI", "Anthropic"]
    },
    "cost_effective": {
        "name": "Cost-Effective",
        "description": "Kostenbewusst mit neuesten effizienten Modellen",
        "cost": "Niedrig",
        "performance": "Gut",
        "models": {
            "classifier_model": "gemini-2.5-flash-lite-preview-06-17",
            "extractor_model": "gpt-4o-mini",
            "synthesizer_model": "gemini-2.0-flash",
            "validator_model_1": "gpt-4o-mini",
            "validator_model_2": "claude-3-5-haiku-20241022"
        },
        "required_apis": ["Google", "OpenAI", "Anthropic"]
    },
    "gemini_only": {
        "name": "🧪 Gemini Only",
        "description": "Nur Google Gemini Modelle (neueste Generation)",
        "cost": "Niedrig",
        "performance": "Gut",
        "models": {
            "classifier_model": "gemini-2.5-flash",
            "extractor_model": "gemini-2.5-pro",
            "synthesizer_model": "gemini-2.5-pro",
            "validator_model_1": "gemini-2.0-flash",
            "validator_model_2": "gemini-2.5-flash"
        },
        "required_apis": ["Google"]
    },
    "openai_only": {
        "name": "🧪 OpenAI Only",
        "description": "Nur OpenAI Modelle (inkl. neueste Reasoning-Modelle)",
        "cost": "Mittel",
        "performance": "Hoch",
        "models": {
            "classifier_model": "gpt-4o-mini",
            "extractor_model": "gpt-4.1",
            "synthesizer_model": "gpt-4o",
            "validator_model_1": "o4-mini",
            "validator_model_2": "o3-mini"
        },
        "required_apis": ["OpenAI"]
    }
}

def find_env_file() -> Path:
    """Findet die .env Datei im Projekt"""
    current_dir = Path(__file__).parent
    # Gehe nach oben bis zum Projekt-Root
    while current_dir.parent != current_dir:
        env_file = current_dir / ".env"
        if env_file.exists():
            return env_file
        current_dir = current_dir.parent
    
    # Fallback: Erstelle .env im ki-wissenssystem Verzeichnis
    ki_dir = Path(__file__).parent.parent.parent
    return ki_dir / ".env"

def read_env_file(env_path: Path) -> Dict[str, str]:
    """Liest die .env Datei und gibt ein Dictionary zurück"""
    env_vars = {}
    if env_path.exists():
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip()
    return env_vars

def write_env_file(env_path: Path, env_vars: Dict[str, str]):
    """Schreibt die Environment-Variablen in die .env Datei"""
    with open(env_path, 'w') as f:
        f.write("# KI-Wissenssystem Environment Configuration\n")
        f.write("# Generated by switch-model-profile.py\n\n")
        
        # API Keys
        f.write("# API Keys\n")
        for key in ['OPENAI_API_KEY', 'ANTHROPIC_API_KEY', 'GOOGLE_API_KEY']:
            value = env_vars.get(key, 'your-api-key-here')
            f.write(f"{key}={value}\n")
        
        f.write("\n# Database Configuration\n")
        f.write(f"NEO4J_URI={env_vars.get('NEO4J_URI', 'bolt://localhost:7687')}\n")
        f.write(f"NEO4J_USER={env_vars.get('NEO4J_USER', 'neo4j')}\n")
        f.write(f"NEO4J_PASSWORD={env_vars.get('NEO4J_PASSWORD', 'password')}\n")
        f.write(f"CHROMA_HOST={env_vars.get('CHROMA_HOST', 'localhost')}\n")
        f.write(f"CHROMA_PORT={env_vars.get('CHROMA_PORT', '8000')}\n")
        
        f.write("\n# Model Configuration\n")
        f.write(f"MODEL_PROFILE={env_vars.get('MODEL_PROFILE', 'premium')}\n")
        
        f.write("\n# Optional: Manual Model Override (uncomment to use)\n")
        f.write(f"# CLASSIFIER_MODEL={env_vars.get('CLASSIFIER_MODEL', '')}\n")
        f.write(f"# EXTRACTOR_MODEL={env_vars.get('EXTRACTOR_MODEL', '')}\n")
        f.write(f"# SYNTHESIZER_MODEL={env_vars.get('SYNTHESIZER_MODEL', '')}\n")
        f.write(f"# VALIDATOR_MODEL_1={env_vars.get('VALIDATOR_MODEL_1', '')}\n")
        f.write(f"# VALIDATOR_MODEL_2={env_vars.get('VALIDATOR_MODEL_2', '')}\n")

def get_current_profile() -> str:
    """Ermittelt das aktuell aktive Profil"""
    env_path = find_env_file()
    env_vars = read_env_file(env_path)
    return env_vars.get('MODEL_PROFILE', 'premium')

def show_current_profile():
    """Zeigt das aktuelle Profil an"""
    current = get_current_profile()
    profile = PROFILES.get(current, PROFILES['premium'])
    
    print(f"🎯 Aktuelles Profil: {profile['name']} ({current})")
    print(f"📝 Beschreibung: {profile['description']}")
    print(f"💰 Kosten: {profile['cost']}")
    print(f"⚡ Performance: {profile['performance']}")
    print(f"🔑 Benötigte APIs: {', '.join(profile['required_apis'])}")
    
    print("\n🤖 Modell-Zuordnung:")
    for role, model in profile['models'].items():
        role_name = role.replace('_', ' ').title()
        print(f"  • {role_name}: {model}")

def list_profiles():
    """Listet alle verfügbaren Profile auf"""
    current = get_current_profile()
    
    print("📋 Verfügbare Modell-Profile:\n")
    
    for profile_id, profile in PROFILES.items():
        status = "✅ AKTIV" if profile_id == current else "⚪"
        print(f"{status} {profile['name']} ({profile_id})")
        print(f"   📝 {profile['description']}")
        print(f"   💰 Kosten: {profile['cost']} | ⚡ Performance: {profile['performance']}")
        print(f"   🔑 APIs: {', '.join(profile['required_apis'])}")
        print()

def switch_profile(profile_id: str):
    """Wechselt zu einem anderen Profil"""
    if profile_id not in PROFILES:
        print(f"❌ Unbekanntes Profil: {profile_id}")
        print(f"Verfügbare Profile: {', '.join(PROFILES.keys())}")
        return False
    
    env_path = find_env_file()
    env_vars = read_env_file(env_path)
    
    # Profil wechseln
    env_vars['MODEL_PROFILE'] = profile_id
    
    # .env Datei aktualisieren
    write_env_file(env_path, env_vars)
    
    profile = PROFILES[profile_id]
    print(f"✅ Profil gewechselt zu: {profile['name']} ({profile_id})")
    print(f"📁 Konfiguration gespeichert in: {env_path}")
    
    # Warnung für benötigte API Keys
    missing_apis = []
    for api in profile['required_apis']:
        key_name = f"{api.upper()}_API_KEY"
        if not env_vars.get(key_name) or env_vars.get(key_name) == 'your-api-key-here':
            missing_apis.append(api)
    
    if missing_apis:
        print(f"\n⚠️  Fehlende API Keys für: {', '.join(missing_apis)}")
        print("   Bitte konfigurieren Sie die entsprechenden API Keys in der .env Datei")
    
    print("\n🔄 Starten Sie die Anwendung neu, um die Änderungen zu übernehmen")
    return True

def interactive_mode():
    """Interaktiver Modus für Profil-Auswahl"""
    print("🎛️  Interaktiver Profil-Wechsel\n")
    
    list_profiles()
    
    while True:
        try:
            choice = input("Welches Profil möchten Sie aktivieren? (Name oder 'q' zum Beenden): ").strip().lower()
            
            if choice == 'q':
                print("👋 Auf Wiedersehen!")
                break
                
            if choice in PROFILES:
                if switch_profile(choice):
                    break
            else:
                print(f"❌ Unbekanntes Profil: {choice}")
                print("Verfügbare Profile:", ", ".join(PROFILES.keys()))
                
        except KeyboardInterrupt:
            print("\n👋 Auf Wiedersehen!")
            break

def main():
    parser = argparse.ArgumentParser(
        description="KI-Wissenssystem Model Profile Switcher",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Beispiele:
  %(prog)s --show              # Aktuelles Profil anzeigen
  %(prog)s --list              # Alle Profile auflisten  
  %(prog)s gemini_only         # Zu Gemini-Only Profil wechseln
  %(prog)s openai_only         # Zu OpenAI-Only Profil wechseln
  %(prog)s premium             # Zu Premium Profil wechseln
  %(prog)s --interactive       # Interaktiver Modus
        """
    )
    
    parser.add_argument('profile', nargs='?', help='Profil-Name zum Aktivieren')
    parser.add_argument('--show', '-s', action='store_true', help='Aktuelles Profil anzeigen')
    parser.add_argument('--list', '-l', action='store_true', help='Alle Profile auflisten')
    parser.add_argument('--interactive', '-i', action='store_true', help='Interaktiver Modus')
    
    args = parser.parse_args()
    
    if args.show:
        show_current_profile()
    elif args.list:
        list_profiles()
    elif args.interactive:
        interactive_mode()
    elif args.profile:
        switch_profile(args.profile)
    else:
        # Kein Argument: Zeige aktuelles Profil und Liste
        show_current_profile()
        print("\n" + "="*60 + "\n")
        list_profiles()

if __name__ == "__main__":
    main() 